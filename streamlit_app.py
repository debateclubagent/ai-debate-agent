import os
import requests
from typing import List
import streamlit as st

# ä» Streamlit Secrets ä¸­è·å– Hugging Face Token
HF_TOKEN = st.secrets["HF_TOKEN"]
headers = {"Authorization": f"Bearer {HF_TOKEN}"}

# æ¨¡å‹è¯·æ±‚å‡½æ•°ï¼Œæ”¯æŒä¼ å…¥ä¸åŒæ¨¡å‹åœ°å€
def query_model(prompt: str, model_url: str) -> str:
    payload = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": 200,
            "temperature": 0.7,
            "do_sample": True
        }
    }
    response = requests.post(model_url, headers=headers, json=payload)
    try:
        result = response.json()
        if isinstance(result, dict) and result.get("error"):
            return f"[é”™è¯¯] æ¨¡å‹è¿”å›ï¼š{result['error']}"
        return result[0]["generated_text"].strip()
    except Exception as e:
        return f"[é”™è¯¯] æ¨¡å‹å“åº”è§£æå¤±è´¥ï¼š{str(e)}"

# å¤šæ¨¡å‹ä»£ç†ç±»
class Agent:
    def __init__(self, name, position, system_prompt, model_url):
        self.name = name
        self.position = position
        self.system_prompt = system_prompt
        self.model_url = model_url

    def respond(self, topic, previous_statements=None):
        context = ""
        if previous_statements:
            context += "\nä»¥ä¸‹æ˜¯ä¸Šä¸€è½®çš„å‘è¨€æ‘˜è¦ï¼Œè¯·å‚è€ƒå¹¶å›åº”ï¼š\n"
            for s in previous_statements:
                s = s.split("]:", 1)[1].strip() if "]:" in s else s
                context += f"- {s}\n"
        prompt = f"ä½ æ˜¯{self.name}ï¼Œä½ çš„ç«‹åœºæ˜¯{self.position}ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©æ¨è¿›ä¸€ä¸ªå…±åŒç›®æ ‡ï¼šâ€œä¸ºå®¶é•¿åˆ¶å®šAIè‚²å„¿æŒ‡å—â€ã€‚{self.system_prompt}\nè¯·ä½ å°±ä»¥ä¸‹è¯é¢˜é˜è¿°ä½ çš„è§‚ç‚¹ï¼Œå¹¶å‚è€ƒä¸Šä¸€è½®çš„å‘è¨€ï¼š\nè¯é¢˜ï¼š{topic}{context}"
        return f"[{self.name} - {self.position}]: {query_model(prompt, self.model_url)}"

# æ‰¹åˆ¤æ€§æ€»ç»“ä»£ç†
class JudgeAgent:
    def __init__(self, name, model_url):
        self.name = name
        self.model_url = model_url

    def evaluate(self, statements, goal):
        summary_prompt = f"ä½ æ˜¯{self.name}ï¼Œè¯·æ ¹æ®ä»¥ä¸‹å¤šè½®è®¨è®ºå†…å®¹ï¼Œå¯¹æ¯ä½å‘è¨€è€…çš„è§‚ç‚¹è¿›è¡Œæ€»ç»“ä¸è¯„ä»·ï¼Œå¹¶åˆ¤æ–­è¿™äº›è§‚ç‚¹æ˜¯å¦æœ‰åŠ©äºå®ç°å…±åŒç›®æ ‡ï¼š{goal}ã€‚\n\nå‘è¨€è®°å½•ï¼š\n" + "\n".join(statements)
        return f"[{self.name} - æ€»ç»“è€…]: {query_model(summary_prompt, self.model_url)}"

# Streamlit ç•Œé¢
st.title("ğŸ—£ï¸ å¤šè§’è‰² AI è¾©è®ºç³»ç»Ÿ")

# ç”¨æˆ·è¾“å…¥
topic = st.text_input("è¯·è¾“å…¥è¾©é¢˜ï¼ˆå¦‚ï¼šæ˜¯å¦è®©AIå‚ä¸å„¿ç«¥æ•™è‚²ï¼Ÿï¼‰", "æ˜¯å¦åº”è¯¥è®©AIå‚ä¸å„¿ç«¥æ•™è‚²ï¼Ÿ")

# å¼€å§‹æŒ‰é’®
if st.button("å¼€å§‹è¾©è®º"):
    agents = [
        Agent("ä¹è§‚æ´¾", "æ”¯æŒè€…", "ä½ æ€»æ˜¯å€¾å‘äºçœ‹åˆ°äº‹æƒ…ç§¯æçš„ä¸€é¢ï¼Œé¼“åŠ±å°è¯•å’Œåˆ›æ–°ã€‚",
              "https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta"),
        Agent("æ‚²è§‚æ´¾", "æ‰¹åˆ¤è€…", "ä½ æ€»æ˜¯å¼ºè°ƒæ½œåœ¨é£é™©å’Œä¸ç¡®å®šæ€§ï¼Œè°¨æ…ä¿å®ˆã€‚",
              "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1"),
        Agent("ä¸­ç«‹æ´¾", "åˆ†æè€…", "ä½ æ³¨é‡å¹³è¡¡å„ç§è§‚ç‚¹ï¼Œæå‡ºå®¢è§‚çš„åˆ†æå’Œå¯¹æ¯”ã€‚",
              "https://api-inference.huggingface.co/models/meta-llama/Llama-3.2-3B-Instruct")
    ]

    judge = JudgeAgent("AIè¯„è®®å®˜", "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1")
    goal = "ä¸ºå®¶é•¿åˆ¶å®šAIè‚²å„¿æŒ‡å—"

    st.markdown(f"### ğŸ¯ å…±åŒç›®æ ‡ï¼š{goal}")

    history = []
    for round_num in range(2):
        st.markdown(f"#### ç¬¬ {round_num + 1} è½®å‘è¨€")
        current_round = []
        for agent in agents:
            previous = history[-len(agents):] if history else None
            with st.spinner(f"{agent.name} å‘è¨€ä¸­..."):
                statement = agent.respond(topic, previous)
                st.markdown(statement)
                current_round.append(statement)
        history.extend(current_round)

    st.markdown("---")
    st.markdown("### ğŸ§  æ€»ç»“è¯„ä»·")
    with st.spinner("è¯„è®®å®˜æ€»ç»“ä¸­..."):
        summary = judge.evaluate(history, goal)
        st.markdown(summary)
