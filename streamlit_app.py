import streamlit as st
import requests
import json

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="é—®ç­”åŠ©æ‰‹")
st.title("ğŸ§  é—®ç­”ç”Ÿæˆå™¨")

# ä½¿ç”¨ Streamlit secrets è¯»å– Hugging Face Token
API_URL = "https://api-inference.huggingface.co/models/tiiuae/falcon-7b-instruct"
headers = {
    "Authorization": f"Bearer {st.secrets['HF_TOKEN']}"
}

def query(payload):
    response = requests.post(API_URL, headers=headers, json=payload)
    return response.json()

# ç”¨æˆ·è¾“å…¥é—®é¢˜
question = st.text_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š")

if question:
    with st.spinner("æ­£åœ¨è°ƒç”¨ Hugging Face æ¨¡å‹ç”Ÿæˆå›ç­”..."):
        prompt = f"é—®é¢˜ï¼š{question}\nè¯·ç®€æ´åœ°ç”¨ä¸­æ–‡å›ç­”è¿™ä¸ªé—®é¢˜ï¼š"
        output = query({
            "inputs": prompt,
            "options": {"wait_for_model": True}
        })

        if isinstance(output, list) and 'generated_text' in output[0]:
            st.subheader("æ¨¡å‹å›ç­”")
            st.write(output[0]['generated_text'].replace(prompt, "").strip())
        else:
            st.error("âŒ æ¨¡å‹æ²¡æœ‰è¿”å›æœ‰æ•ˆçš„ç»“æœã€‚è¯·ç¨åå†è¯•æˆ–æ›´æ¢æ¨¡å‹ã€‚")
